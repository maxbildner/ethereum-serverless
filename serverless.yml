# Welcome to Serverless!
#
# This file is the main config file for your service.
# It's very minimal at this point and uses default values.
# You can always add more config options for more control.
# We've included some commented out config examples here.
# Just uncomment any of them to get that config option.
#
# For full config options, check the docs:
#    docs.serverless.com
#
# Happy Coding!

# Below doesn't work!! (for next js)
# - see docs: https://serverless-nextjs.com/docs/faq/
# myNextApp:
#   component: serverless-next.js

service: ethereum-serverless
# app and org for use with dashboard.serverless.com
#app: your-app-name
#org: your-org-name

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
frameworkVersion: "2"

provider:
  name: aws
  runtime: nodejs12.x
  lambdaHashingVersion: 20201221
  profile: max.bildner # this was set up when we ran "serverless config credentials..."
  environment: # adding environment variables- process.env.tableName
    tableName: ${self:custom.tableName}
  iamRoleStatements: # add permissions so lambda can access our dynamoDB
    - Effect: Allow # an array
      Action:
        - dynamoDB:* # * = everymethod in the dynamoDB class
      Resource: "*" # everything

plugins:
  - serverless-s3-sync
  - serverless-webpack

# have each of the lambdas packaged individually
package:
  individually: true

custom:
  tableName: users
  s3Sync: # a list of buckets and files we want to sync up
    - bucketName: ethereum-serverless-kickstart-bucket
      localDir: UploadData # folder on our local machine we want to upload to s3

# you can overwrite defaults here
#  stage: dev
#  region: us-east-1

# you can add statements to the Lambda function's IAM Role here
#  iam:
#    role:
#      statements:
#        - Effect: "Allow"
#          Action:
#            - "s3:ListBucket"
#          Resource: { "Fn::Join" : ["", ["arn:aws:s3:::", { "Ref" : "ServerlessDeploymentBucket" } ] ]  }
#        - Effect: "Allow"
#          Action:
#            - "s3:PutObject"
#          Resource:
#            Fn::Join:
#              - ""
#              - - "arn:aws:s3:::"
#                - "Ref" : "ServerlessDeploymentBucket"
#                - "/*"

# you can define service wide environment variables here
#  environment:
#    variable1: value1

# you can add packaging information here
#package:
#  patterns:
#    - '!exclude-me.js'
#    - '!exclude-me-dir/**'
#    - include-me.js
#    - include-me-dir/**

functions:
  hello:
    handler: handler.hello
  getUser:
    handler: lambdas/endpoints/getUser.handler
    events: # trigger for the function
      - http: # create an api endpoint at "/get-user/{ID}"
          path: get-user/{ID} # whatever the client passes in ID, will be a pathParameter in event
          method: GET
          cors: true
  getUserAge:
    handler: lambdas/endpoints/getUserAge.handler
    events: # trigger for the function
      - http: # create an api endpoint at "/get-user-age/{ID}"
          path: get-user-age/{ID} # whatever the client passes in ID, will be a pathParameter in event
          method: GET
          cors: true
  createUserAge:
    handler: lambdas/endpoints/createUserAge.handler
    events:
      - http:
          path: create-user-age/{ID}
          method: POST # GET can only pass data from client in url path/header
          cors: true

#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - httpApi:
#          path: /users/create
#          method: get
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp
#      - alb:
#          listenerArn: arn:aws:elasticloadbalancing:us-east-1:XXXXXX:listener/app/my-load-balancer/50dc6c495c0c9188/
#          priority: 1
#          conditions:
#            host: example.com
#            path: /hello

#    Define function environment variables here
#    environment:
#      variable2: value2

resources:
  Resources:
    DemoBucketUpload: # AWS S3 bucket name we want to create
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ethereum-serverless-kickstart-bucket # must be unique!
    MyDynamoDbTable: # name of resource
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:custom.tableName} # refers to "users" defined in custom field above
        AttributeDefinitions:
          - AttributeName: ID # use hyphen "-" to indiciate array
            AttributeType: S # string
        KeySchema:
          - AttributeName: ID
            KeyType: HASH # this helps dynamo know what format the attributes are in
        # BillingMode = how is aws going to let us add/remove/update stuff in table
        BillingMode: PAY_PER_REQUEST # just pay everytime we read/write from table

# you can add CloudFormation resource templates here
# resources:
#  Resources:
#    NewResource:
#      Type: AWS::S3::Bucket
#      Properties:
#        BucketName: my-new-bucket
#  Outputs:
#     NewOutput:
#       Description: "Description for the output"
#       Value: "Some output value"
